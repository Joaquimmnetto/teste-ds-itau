{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Teste Data Science Itaú\"\noutput: html_notebook\n---\n\n## Preambulo\n\nPs: Os cabeçalhos das questões foram feitos a partir do que eu lembrei deles, mas as respostas foram as mesmas enviadas para o teste original.\n\n```{r}\nrequire(data.table)\nrequire(reticulate)\nrandom = import('random')\nrandom$seed(as.numeric(42))\nset.seed(42)\n\nskmetrics = import(\"sklearn.metrics\")\n```\n\n## Questão 1\n\nQual o numero de clusters mais adequado para os dados em agrupamento_Q1.csv, e quais os centroides desses clusters, usando os centroides em agrup_centroides_Q1.csv e KMeans?\n\n```{r}\nq1_cntr = fread('datasets/agrup_centroides_Q1.csv', \n                col.names = c(\"id\",\"x1\",\"x2\",\"x3\",\"x4\"),\n                colClasses = c(\"factor\",\"numeric\",\"numeric\",\"numeric\",\"numeric\")\n              )\nq1_points = fread('datasets/agrupamento_Q1.csv',\n                col.names = c(\"x1\",\"x2\",\"x3\",\"x4\"),\n                colClasses = c(\"numeric\",\"numeric\",\"numeric\",\"numeric\")\n                )\nq1_cntr$id = NULL\n```\n\n```{r}\nsilhouettes = 1:12\nsilhouettes[1] = -Inf\ncenters = list()\n\nfor(n in 2:12){\n  clt = import('sklearn.cluster')\n  y = clt$KMeans(n_clusters = as.integer(n), max_iter = as.integer(10), init = q1_cntr[1:n], random_state = as.integer(42))\n  clusters = y$fit_predict(q1_points) \n  if(n==5){ print(y$cluster_centers_)}\n  #clusters = as.factor(apply(distances, 1, which.min))\n  \n  scores = skmetrics$silhouette_score(X=q1_points, labels=clusters)\n  silhouettes[n] = scores\n}\nprint(silhouettes)\n```\n\nResposta escolhida a partir do score médio da metrica de silhouette para cada passo. k=5 teve o melhor resultado com 0.487 como valor de silhouette.\n\nO posicionamento dos centróides para esse caso é:\n[1,]  1.00809727 0.0056562568 -0.006058822  0.029329272\n[2,]  0.99556174 0.0006261532 -0.007804098  1.001521200\n[3,]  0.99595270 0.0064627322  0.999718008  0.003147213\n[4,] -0.03471473 0.0163162909  0.010426475 -0.016240750\n[5,]  0.99074009 0.9930477735  0.969936615 -0.004064823\n\n\n## Questão 3\n\nUse naive-bayes com validação holdout, para descobrir a acuracia media dos conjuntos de treino e validação nos dados no arquivo classificacao_Q3.csv. O tamanho do conjunto de validação é 500.\n\n```{r}\nq3_clf = fread('datasets/classificacao_Q3.csv', \n                col.names = c(\"genero\",\"idade\",\"escolaridade\",\"profissao\",\"target\"),\n                colClasses = c(\"factor\",\"factor\",\"factor\",\"factor\",\"factor\")\n              )\nq3_clf$genero = as.numeric(q3_clf$genero)\nq3_clf$idade = as.numeric(q3_clf$idade)\nq3_clf$escolaridade = as.numeric(q3_clf$escolaridade)\nq3_clf$profissao = as.numeric(q3_clf$profissao)\n\nq3_X = q3_clf\nq3_Y = q3_clf$target\ntreino = 1:500\nval = 501:nrow(q3_clf)\n\nq3_X$target = NULL\n\n```\n\n```{r}\nnb = import('sklearn.naive_bayes')\n\nclf = nb$GaussianNB()\nclf = clf$fit(q3_X[treino],q3_Y[treino])\n\nclf$score(q3_X[treino],q3_Y[treino])\nclf$score(q3_X[val],q3_Y[val])\n\n```\nA partir do citado no enunciado, utlizamos a validação holdout, dividindo o conjunto em conjuntos de treino e validação independentes, no caso, a proporção pedida foi de 50/50.\nCriamos um conjunto de treinamento, com 500 entradas, que nos deu acurácia de treinamento (utilizando os Y de treinamento para o cálculo da métrica) igual a 0.792.\n\nTambém criamos um conjunto de validação, também com 500 entradas, que nos deu acurácia média igual a 0.762, prevendo valores a partir do modelo treinado pelo conjunto de treinamento descrito anteriormente.\n\n\n## Questão 4\n\nUsando 10-fold cross validation, use um modelo KNN (k=15, distancia euclidiana), para descobrir a acurácia média de validação dos dados em classificacao_Q4.csv.\n\n```{r}\nq4_clf = fread('datasets/classificacao_Q4.csv')\nq4_clf$target = as.factor(q4_clf$target)\nq4_Y = q4_clf$target\n\nq4_X = q4_clf\nq4_X$target = NULL\n\n```\n\n```{r}\nknn = import('sklearn.neighbors')\nmodel_select = import('sklearn.model_selection')\nkfold = model_select$KFold(n_splits=as.integer(10), random_state=as.integer(42), shuffle=FALSE)\nsplit = kfold$split(q4_clf)\naccuracies = 1:10\nfor(i in 1:10){\n  splits = iter_next(split)\n  treino = unlist(splits[1])+1\n  val = unlist(splits[2])+1\n  clf = knn$KNeighborsClassifier(n_neighbors = as.integer(15), p = as.integer(2))\n  clf = clf$fit(q4_X[treino], q4_Y[treino])\n  accuracies[i] = clf$score(q4_X[val], q4_Y[val])\n}\nprint(accuracies)\nmean(accuracies)\nsd(accuracies)\n```\n\nSeguindo o enunciado, a base foi dividida de acordo com 10-fold cross-validation, gerando conjuntos de validação com 150 linhas, e de treino com 1350 linhas.\n\nAs acurácias para cada um dos passos da validação cruzada estão abaixo\n 0.686, 0.660, 0.620, 0.653, 0.646, 0.666, 0.646, 0.653,\n 0.680, 0.606\nFinalmente a média dessas acurácias foi de 0.652, com um desvio padrão de 0.024\n\n\n## Questão 6\n\nUsando cross-validation leave-one-out e um algoritimo de regressão linear Ridge, com regularização R2 e parametro de regularização igual a 1.7, dê o RMSE médio de treino e validação para os dados no arquivo regressao_q6.csv\n\n```{r}\nq6_reg = fread('datasets/regressao_q6.csv')\nq6_Y = q6_reg$target\n\nq6_X = q6_reg\nq6_X$target = NULL\n\n\n```\n\n```{r}\nlr = import('sklearn.linear_model')\nmodel_select = import('sklearn.model_selection')\nloo = model_select$LeaveOneOut()\nsplit = loo$split(q6_reg)\n\nscores_treino = 1:nrow(q6_reg)\nscores_val = 1:nrow(q6_reg)\n\nfor(i in 1:nrow(q6_reg)){\n  splits = iter_next(split)\n  treino = unlist(splits[1])+1\n  val = unlist(splits[2])+1\n  \n  clf = lr$Ridge(alpha = as.numeric(1.7))\n  clf = clf$fit(q6_X[treino], q6_Y[treino])\n  \n  tr_pred_Y = clf$predict(q6_X[treino])\n  scores_treino[i] = skmetrics$mean_squared_error(q6_Y[treino], tr_pred_Y)\n  \n  pred_Y = clf$predict(q6_X[val])\n  scores_val[i] = skmetrics$mean_squared_error(list(q6_Y[val]), list(pred_Y))\n}\n\nsummary(sqrt(scores_treino))\nsd(sqrt(scores_treino))\nsummary(sqrt(scores_val))\nsd(sqrt(scores_val))\n\n\n```\nDe acordo com o enunciado, dividimos o dados usando a validação Leave-one-out, onde somente uma entrada é validada por vez.\n\nFoi usado o algoritimo de regressão linear Ridge, com um alpha=1.7. O RMSE médio para o conjunto de treinamento foi  27.43 (std.dev=0.017), enquanto o RMSE médio para o conjunto de validação foi 22.05 (std.dev=16.76).\n\nTreino:\nMin. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  27.31   27.43   27.44   27.43   27.44   27.44 \nValidação:  \n  Min.    1st Qu.   Median  Mean    3rd Qu.   Max. \n 0.05314  8.84139 19.01363 22.05880 31.83349 90.76112 \n   \n## Questão 7\n\nUsando uma árvore de regressão sem podas, com quebras baseadas no MSE e 10-fold cross validation, dê os MAE médios para treino e validação para os dados em regressao_q7.csv.\n\n```{r}\nq7_reg = fread('datasets/regressao_q7.csv')\n\nq7_Y = q7_reg$target\n\nq7_X = q7_reg\nq7_X$target = NULL\n\n```\n\n\n```{r}\nknn = import('sklearn.tree')\nmodel_select = import('sklearn.model_selection')\nkfold = model_select$KFold(n_splits=as.integer(10), random_state=as.integer(42), shuffle=FALSE)\nsplit = kfold$split(q7_reg)\n\nscores_treino = 1:10\nscores_val = 1:10\nfor(i in 1:10) {\n  splits = iter_next(split)\n  treino = unlist(splits[1])+1\n  val = unlist(splits[2])+1\n  \n  clf = knn$DecisionTreeRegressor(criterion = 'mse', random_state = as.integer(42))\n  clf = clf$fit(q7_X[treino], q7_Y[treino])\n  tr_pred_Y = clf$predict(q7_X[treino])\n  scores_treino[i] = skmetrics$mean_absolute_error(q7_Y[treino], tr_pred_Y)\n  \n  pred_Y = clf$predict(q7_X[val])\n  scores_val[i] = skmetrics$mean_absolute_error(q7_Y[val], pred_Y)\n}\n```\n\n```{r}\n\nsummary(scores_treino)\nsd(scores_treino)\n\nsummary(scores_val)\nsd(scores_val)\n\n```\n\nComo expressado no enunciado, construímos uma arvore de regressão sem podas, e com quebras baseadas no MSE, usando 10-fold cross-validation como o método de validação.\n\nNisso, chegamos em um MAE médio de 6.898e-08 (std.dev=1.45e-07) para os dados de treino, e um MAE médio de 52.41 (std.dev=2.525) para os dados de validação. Pela diferença do MAE médio de treino para o MAE médio de validação, fica claro que essa árvore está sofrendo de overfitting, provavelmente devido a falta podas nesta.\n\n",
    "created" : 1531171646049.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "437823071",
    "id" : "4483A5A8",
    "lastKnownWriteTime" : 1531188063,
    "last_content_update" : 1531188063989,
    "path" : "C:/Users/KithLenovo/Desktop/teste_itau/teste_itau.rmd",
    "project_path" : "teste_itau.rmd",
    "properties" : {
        "chunk_output_type" : "inline"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}